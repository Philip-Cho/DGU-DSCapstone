Welcome to buy ties at a science in the last four videos recovered algorithms that's required. Supervised learning ensembles and logistic regression. Let's take a break from it. And look at some unsupervised, learning algorithms, algorithms for clustering clustering is about drooping. Similar objects. For example, similar individuals may have similar tastes and needs similar products and possibly be interchangeable. Do they need of a customer? What do we mean by similar? For example, for individuals? We can look at age gender income. And so, it is pretty obvious that what appeals to a 20-year old is quite different from what it feels to 60 year old. We can group, people objects events, music movies location, and just about anything. We can think of.  If you think of buying a house, you can look at the number of bathrooms. And number of bedrooms. If it is a condo apartment duplex and so on, you can do it neighborhoods by characteristics and then find multiple houses in similar neighborhoods that can answer the needs of a buyer.  Similarity is a measure of distance between objects 12 plus touring is to figure out how to express the characteristics in terms of numbers that say we want the group hair. Dye by color. It is not obvious. How close is brown and Auburn are. But if you come for the colors to an RGB representation, we now have three numbers that can be used for similarities.  What are the algorithms available for clustering? There are many algorithms available? For example, here's a list of algorithms that are part of the S killer in library.  There are multiple approaches to clustering. We can use a top-down or bottom-up approach. For example, do we know how many clusters we want? We also have to consider the number of data points to process and I was specifically, Jordan performs. We will only cover a few algorithms here. Starting with. Tammy's K means is probably the best-known clustering algorithm and probably the easiest to understand K stands for the number of clusters. We want, here's an example of how it works, the animation on my right shows the entire process. The first step is to pick a starting points.  The easiest sister picked a distinct points as cluster centers in the upper-left image. We picked the Four Points. Farthest to the left. The next step is to associate all the point to discuss our centers as shown in the second image note, that this process left one center with no Associated points. Once this is done. We resent her the Clusters and repeat the process until a number of iterations is done or if the center movements are blue, a decided threshold.  The choice of starting points impacts the result. So it makes sense to repeat the process with other centres. When we looked at the starting image. We may have visualized different clusters than the ones we ended up with.  How do we decide on the number of clusters? We can try a different number clusters and see the impact of the distance from the cluster centers in the diagram. Here. We see a quick drop at the start increasing the number of clusters. This is called the elbow method. We pick a value where the curve is. Another approach is to build a cluster is from the bottom up. I'm here shows the number of clusters and now they would group to reduce their numbers. This was done using the, a deliberative clustering algorithm the bottom layer of the right of the diagram shows, 50 plus there is, and how they would group together to merge together.  The last thing I want to mention is dbscan, which stands for density, based spatial, clustering of applications with noise.  With this elderly, then we can eliminate outliers. So they don't impact are clustering the image on my right shows two clusters. Each cluster different shades between the readings that are in a dance-off core area and the ones that are still part of the Clusters, but I'm not part of the core samples. Finally. We see the outliers values. The great. That are not part of a cluster and are considered noise. The number of clusters is automatically decided based on density parameters.  In the next video will see a use case application of these algorithms. See you next time. I'm by Ties That a science and don't forget to subscribe. 