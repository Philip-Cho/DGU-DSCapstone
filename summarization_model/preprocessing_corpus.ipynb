{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e16fa8",
   "metadata": {},
   "source": [
    "### 선행 작업\n",
    "1. wget으로 데이터 압축파일(.gz) 다운로드\n",
    "2. 모든 압축파일 압출 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e86c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.data import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4af56ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_lst=[]\n",
    "nums=[]        # 작업한 파일 번호 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cbae195",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lynn1\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "tokenizer = load('tokenizers/punkt/english.pickle')   # nltk.sent_tokenizer가 불러오는 파일\n",
    "extra_abbreviation = [    \n",
    "    'RE', 're', 'pat', 'no', 'nos', 'vol', 'jan', 'feb', 'mar', 'apr', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec',\n",
    "    'eng', 'ser', 'ind', 'ed', 'pp', 'e.g', 'al', 'T.E.N.S', 'E.M.S', 'F.E', 'U.H.T.S.T', 'degree', '/g', 'm',\n",
    "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z'\n",
    "]\n",
    "tokenizer._params.abbrev_types.update(extra_abbreviation)   # _params로 파라미터에 직접 접근, 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b578b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_file = 100   # s2-corpus-000 등 파일 번호\n",
    "end_file = 200\n",
    "data_dir = 'C:/Users/lynn1/OneDrive/바탕 화면/Capstone/data/open_research'\n",
    "\n",
    "# for i in range(start_file, end_file+1):\n",
    "#     old_name = data_dir + '/s2-corpus-00{}'.format(i)\n",
    "#     new_name = old_name + '.json'\n",
    "#     os.rename(old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5d00c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 > 1976694|101 > 1996265|102 > 2015924|103 > 2035380|104 > 2055092|105 > 2074758|106 > 2094333|107 > 2113841|108 > 2133355|109 > 2152939|110 > 2172559|111 > 2192182|112 > 2211809|113 > 2231370|114 > 2250971|115 > 2270550|116 > 2290290|117 > 2309981|118 > 2329631|119 > 2349287|120 > 2368937|121 > 2388666|122 > 2408316|123 > 2427923|124 > 2447543|125 > 2466983|126 > 2486519|127 > 2506085|128 > 2525623|129 > 2545297|130 > 2564842|131 > 2584449|132 > 2603956|133 > 2623464|134 > 2643020|135 > 2662518|136 > 2682099|137 > 2701601|138 > 2721228|139 > 2740693|140 > 2760181|141 > 2779909|142 > 2799421|143 > 2819129|144 > 2838682|145 > 2858268|146 > 2877974|147 > 2897512|148 > 2916891|149 > 2936264|150 > 2955762|151 > 2975344|152 > 2994911|153 > 3014411|154 > 3034032|155 > 3053797|156 > 3073334|157 > 3093021|158 > 3112693|159 > 3132233|160 > 3151879|161 > 3171239|162 > 3190796|163 > 3210320|164 > 3229935|165 > 3249512|166 > 3269112|167 > 3288730|168 > 3308248|169 > 3327784|170 > 3347296|171 > 3367049|172 > 3386658|173 > 3406189|174 > 3425827|175 > 3445421|176 > 3464882|177 > 3484410|178 > 3504013|179 > 3523498|180 > 3542942|181 > 3562521|182 > 3582096|183 > 3601552|184 > 3621012|185 > 3640596|186 > 3660099|187 > 3679617|188 > 3699151|189 > 3718659|190 > 3738212|191 > 3757917|192 > 3777323|193 > 3796767|194 > 3816223|195 > 3835749|196 > 3855348|197 > 3875173|198 > 3894750|199 > 3914207|200 > 3933902|"
     ]
    }
   ],
   "source": [
    "# paperAbstract 데이터만 추출\n",
    "for i in range(start_file, end_file+1):\n",
    "    if i<10:\n",
    "        idx = '00{}'.format(i)\n",
    "    elif i<100:\n",
    "        idx = '0{}'.format(i)\n",
    "    else:\n",
    "        idx = '{}'.format(i)\n",
    "        \n",
    "    with jsonlines.open(data_dir+'/s2-corpus-{}'.format(idx), 'r') as file:\n",
    "        data_lst = [line['paperAbstract'] for line in file if line['paperAbstract']!='']\n",
    "        whole_lst = whole_lst + data_lst\n",
    "    nums.append(i)\n",
    "    \n",
    "    print(i, '>', len(whole_lst), end='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bfb983c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 코퍼스 파일의 paperAbstract 문장으로 분리하여 txt 파일에 저장(계속 이어씀)\n",
    "# whole_lst에 모든 데이터 저장 후 한번에 생성하기\n",
    "sent_file = open(data_dir+'/separate_sents.txt', 'a', encoding='utf-8')\n",
    "no_blank = False\n",
    "for line in whole_lst:\n",
    "    if line=='':\n",
    "        break\n",
    "    if line.strip()=='':\n",
    "        if no_blank:\n",
    "            continue\n",
    "        sent_file.write(f'{line}')\n",
    "    else:\n",
    "        result_ = nltk.sent_tokenize(line)   # 문장 구조 학습한 모델 -> 약어에 쓰이는 마침표 등 학습됨\n",
    "        result = [f'{cul_line}\\n' for cul_line in result_]\n",
    "        for save_line in result:\n",
    "            sent_file.write(save_line)\n",
    "            \n",
    "sent_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc083b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1",
   "language": "python",
   "name": "pytorch_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
